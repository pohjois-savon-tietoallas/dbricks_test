<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1 Databricks Connect | _main.utf8</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="1 Databricks Connect | _main.utf8" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1 Databricks Connect | _main.utf8" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  

<link rel="next" href="text-mining-with-sparklyr.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="databricks-connect.html"><a href="databricks-connect.html"><i class="fa fa-check"></i><b>1</b> Databricks Connect</a><ul>
<li class="chapter" data-level="1.1" data-path="databricks-connect.html"><a href="databricks-connect.html#background"><i class="fa fa-check"></i><b>1.1</b> Background</a></li>
<li class="chapter" data-level="1.2" data-path="databricks-connect.html"><a href="databricks-connect.html#cluster-setup"><i class="fa fa-check"></i><b>1.2</b> Cluster setup</a></li>
<li class="chapter" data-level="1.3" data-path="databricks-connect.html"><a href="databricks-connect.html#client-setup"><i class="fa fa-check"></i><b>1.3</b> Client setup</a><ul>
<li class="chapter" data-level="1.3.1" data-path="databricks-connect.html"><a href="databricks-connect.html#install-java"><i class="fa fa-check"></i><b>1.3.1</b> Install Java</a></li>
<li class="chapter" data-level="1.3.2" data-path="databricks-connect.html"><a href="databricks-connect.html#install-python"><i class="fa fa-check"></i><b>1.3.2</b> Install Python</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="databricks-connect.html"><a href="databricks-connect.html#get-connection-values"><i class="fa fa-check"></i><b>1.4</b> Get connection values</a></li>
<li class="chapter" data-level="1.5" data-path="databricks-connect.html"><a href="databricks-connect.html#configure-connection-settings"><i class="fa fa-check"></i><b>1.5</b> Configure connection settings</a></li>
<li class="chapter" data-level="1.6" data-path="databricks-connect.html"><a href="databricks-connect.html#setting-up-rstudio"><i class="fa fa-check"></i><b>1.6</b> Setting up RStudio</a></li>
<li class="chapter" data-level="1.7" data-path="databricks-connect.html"><a href="databricks-connect.html#troubleshoot"><i class="fa fa-check"></i><b>1.7</b> Troubleshoot</a><ul>
<li class="chapter" data-level="1.7.1" data-path="databricks-connect.html"><a href="databricks-connect.html#mac-error-starting-a-spark-session"><i class="fa fa-check"></i><b>1.7.1</b> Mac: Error starting a spark session</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="text-mining-with-sparklyr.html"><a href="text-mining-with-sparklyr.html"><i class="fa fa-check"></i><b>2</b> Text mining with <code>sparklyr</code></a><ul>
<li class="chapter" data-level="2.1" data-path="text-mining-with-sparklyr.html"><a href="text-mining-with-sparklyr.html#data-importg"><i class="fa fa-check"></i><b>2.1</b> Data Importg</a></li>
<li class="chapter" data-level="2.2" data-path="text-mining-with-sparklyr.html"><a href="text-mining-with-sparklyr.html#tidying-data"><i class="fa fa-check"></i><b>2.2</b> Tidying data</a></li>
<li class="chapter" data-level="2.3" data-path="text-mining-with-sparklyr.html"><a href="text-mining-with-sparklyr.html#transform-the-data"><i class="fa fa-check"></i><b>2.3</b> Transform the data</a></li>
<li class="chapter" data-level="2.4" data-path="text-mining-with-sparklyr.html"><a href="text-mining-with-sparklyr.html#data-exploration"><i class="fa fa-check"></i><b>2.4</b> Data Exploration</a></li>
<li class="chapter" data-level="2.5" data-path="text-mining-with-sparklyr.html"><a href="text-mining-with-sparklyr.html#appendix"><i class="fa fa-check"></i><b>2.5</b> Appendix</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="intro-to-sparklyr.html"><a href="intro-to-sparklyr.html"><i class="fa fa-check"></i><b>3</b> Intro to <code>sparklyr</code></a><ul>
<li class="chapter" data-level="3.1" data-path="intro-to-sparklyr.html"><a href="intro-to-sparklyr.html#new-spark-session"><i class="fa fa-check"></i><b>3.1</b> New Spark session</a></li>
<li class="chapter" data-level="3.2" data-path="intro-to-sparklyr.html"><a href="intro-to-sparklyr.html#data-transfer"><i class="fa fa-check"></i><b>3.2</b> Data transfer</a></li>
<li class="chapter" data-level="3.3" data-path="intro-to-sparklyr.html"><a href="intro-to-sparklyr.html#spark-and-dplyr"><i class="fa fa-check"></i><b>3.3</b> Spark and <code>dplyr</code></a></li>
<li class="chapter" data-level="3.4" data-path="intro-to-sparklyr.html"><a href="intro-to-sparklyr.html#feature-transformers"><i class="fa fa-check"></i><b>3.4</b> Feature transformers</a></li>
<li class="chapter" data-level="3.5" data-path="intro-to-sparklyr.html"><a href="intro-to-sparklyr.html#models"><i class="fa fa-check"></i><b>3.5</b> Models</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="testing-databricks-connect-on-desktop-rstudio-.html"><a href="testing-databricks-connect-on-desktop-rstudio-.html"><i class="fa fa-check"></i><b>4</b> Testing databricks connect on desktop RStudio.</a><ul>
<li class="chapter" data-level="4.1" data-path="testing-databricks-connect-on-desktop-rstudio-.html"><a href="testing-databricks-connect-on-desktop-rstudio-.html#connect-to-databricks"><i class="fa fa-check"></i><b>4.1</b> Connect to databricks</a></li>
<li class="chapter" data-level="4.2" data-path="testing-databricks-connect-on-desktop-rstudio-.html"><a href="testing-databricks-connect-on-desktop-rstudio-.html#test"><i class="fa fa-check"></i><b>4.2</b> Test</a></li>
<li class="chapter" data-level="4.3" data-path="testing-databricks-connect-on-desktop-rstudio-.html"><a href="testing-databricks-connect-on-desktop-rstudio-.html#datasets"><i class="fa fa-check"></i><b>4.3</b> Datasets</a></li>
<li class="chapter" data-level="4.4" data-path="testing-databricks-connect-on-desktop-rstudio-.html"><a href="testing-databricks-connect-on-desktop-rstudio-.html#stop"><i class="fa fa-check"></i><b>4.4</b> Stop</a></li>
<li class="chapter" data-level="4.5" data-path="testing-databricks-connect-on-desktop-rstudio-.html"><a href="testing-databricks-connect-on-desktop-rstudio-.html#notes"><i class="fa fa-check"></i><b>4.5</b> Notes</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:title:end-->
<!--bookdown:title:start-->
<div id="databricks-connect" class="section level1">
<h1><span class="header-section-number">1</span> Databricks Connect</h1>
<p><strong>Description:</strong> Instructions for installing and configuring Databricks connect <br>
<strong>Author:</strong> Eric Le Tortorec, Jani Miettinen<br>
<strong>Date:</strong> 2020-03-19<br>
R version 3.6.2 (2019-12-12)</p>
<div id="background" class="section level2">
<h2><span class="header-section-number">1.1</span> Background</h2>
<p>These instructions are for installing and configuring Databricks Connect in order to access Databricks from your local computer. Sorry Windows users, the installation is more complicated for you and will require admin privileges.</p>
<p><strong>NOTE</strong><br />
Once everything has been installed and is running the results that are returned from your analyses will be downloaded onto your computer. Therefore it is absolutely forbidden to analyse KUH data using Databricks Connect!</p>
</div>
<div id="cluster-setup" class="section level2">
<h2><span class="header-section-number">1.2</span> Cluster setup</h2>
<p>Create a Spark cluster with Databricks Runtime version 5.5 or 6.1 and above.</p>
<p>If you are using Databricks Runtime 5.3 or below (unsupported), click the Spark tab and add the following Spark conf: spark.databricks.service.server.enabled true</p>
</div>
<div id="client-setup" class="section level2">
<h2><span class="header-section-number">1.3</span> Client setup</h2>
<div id="install-java" class="section level3">
<h3><span class="header-section-number">1.3.1</span> Install Java</h3>
<p>Download and install <a href="https://www.oracle.com/java/technologies/javase-jdk8-downloads.html">Java 8</a>, which is the only Java version supported by Spark. <strong>NOTE</strong> you have to create an account at Oracle in order to download the installation file.</p>
<p><strong>Windows users</strong>. Java will try to install itself into the <code>Program Files</code>-directory. Path has a space in it, which will cause problems. Install it in <code>C:\\Java</code> instead. You might also have to set the <code>JAVA_HOME</code> variable, more information <a href="https://datathirst.net/blog/2019/4/20/setup-databricks-connect-on-windows">here.</a></p>
</div>
<div id="install-python" class="section level3">
<h3><span class="header-section-number">1.3.2</span> Install Python</h3>
<p>Download and install Python. It is easiest to install Python via <a href="https://www.anaconda.com/distribution/">Anaconda</a>. Anaconda includes a environment management system called conda, which should be used to create a new environment inside which you can install the packages needed for Databricks connect.</p>
<p>The minor version of your client Python installation must be the same as the minor Python version of your Azure Databricks cluster (2.7, 3.5, 3.6, or 3.7). Databricks Runtime 5.x has Python 3.5, Databricks Runtime 5.x ML has Python 3.6, and Databricks Runtime 6.x and Databricks Runtime 6.x ML have Python 3.7.</p>
<p><strong>Windows users</strong>. Anaconda comes with a command line interface called Anaconda Powershell Prompt. Use this to write the code blocks below, unless otherwise instructed.</p>
<p><strong>Mac users</strong>. You can use the terminal to write the commands.</p>
<p>Create the environment with:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="ex">conda</span> create --name dbconnect python=3.7</a></code></pre></div>
<p>Where <code>dbconnect</code> is the name of the environment and <code>python=3.7</code> specifies the version of Python you want to install.</p>
<p>Activate the environment with:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="ex">conda</span> activate dbconnect</a></code></pre></div>
<p>Once inside the new environment configure the environment for Databricks connect. If pyspark has been installed in your environment you will need to uninstall it:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="ex">pip</span> uninstall pyspark</a></code></pre></div>
<p>Then install the Databricks Connect client:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="ex">pip</span> install -U databricks-connect==6.2.*</a></code></pre></div>
<p>Where <code>databricks-connect==6.2.*</code> is the Databricks Runtime version</p>
</div>
</div>
<div id="get-connection-values" class="section level2">
<h2><span class="header-section-number">1.4</span> Get connection values</h2>
<p>In order to connect to Databricks running on Azure, you will need specific information about the cluster you will be connecting to:</p>
<ul>
<li>Databricks host</li>
<li>Cluster ID</li>
<li>Organisation ID</li>
<li>Port</li>
<li>User token</li>
</ul>
<p>This information can be found from the URL of your cluster. E.g.:</p>
<p><a href="https://northeurope.azuredatabricks.net/?o=2208xxxxxxxxxxxx#/setting/clusters/0212-yyyyyy-yyyyyyyy/" class="uri">https://northeurope.azuredatabricks.net/?o=2208xxxxxxxxxxxx#/setting/clusters/0212-yyyyyy-yyyyyyyy/</a></p>
<ul>
<li><p>In this case the <strong>Databricks host</strong> is <a href="https://northeurope.azuredatabricks.net" class="uri">https://northeurope.azuredatabricks.net</a> (The host will change when the KUH cloud environment is moved to West Europe.)</p></li>
<li><p>The <strong>cluster ID</strong> is: 0212-yyyyyy-yyyyyyyy</p></li>
<li><p>The <strong>organisation ID</strong> is the part after ?o= in this case: 2208xxxxxxxxxxxx</p></li>
<li><p>The <strong>port</strong> will be 15001 by default</p></li>
</ul>
<p>Finally, a <strong>user token</strong> needs to be created. Click on the user profile icon in the upper right had corner of the Databricks website, click on <strong>User Settings</strong> and then the <strong>Access Tokens</strong> tab. From there you can create a token, give some information about it in the form of a comment, and spaecify a lifetime. Copy the created token and store it securely.</p>
<p><strong>NOTE</strong><br />
This is like a password, treat it as such!</p>
</div>
<div id="configure-connection-settings" class="section level2">
<h2><span class="header-section-number">1.5</span> Configure connection settings</h2>
<p>Within the Python environment you created before run the following in order to supply the configuration values:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="ex">databricks-connect</span> configure</a></code></pre></div>
<p>You will be presented with a license to accept and then fields in which to supply the values gathered above.</p>
<p>You should now be able to test the connection with:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="ex">databricks-connect</span> test</a></code></pre></div>
<p><strong>NOTE</strong><br />
I was not able to get this to work even though the connection worked through RStudio. I read about the same experience elsewhere as well. Mac gave Warning of Java version <code>WARNING: Java versions &gt;8 are not supported by this SDK</code>.</p>
</div>
<div id="setting-up-rstudio" class="section level2">
<h2><span class="header-section-number">1.6</span> Setting up RStudio</h2>
<p>Start off by downloading and unpacking <a href="https://spark.apache.org/downloads.html">Spark</a> on your computer. Make sure the Hadoop version of Spark is 2.7. Unpack in e.g. <code>C:\\Users\\username\\AppData\\Local\\Apache\\Spark</code>. Make a note of where you unpacked spark.</p>
<p><strong>Windows users</strong><br />
Spark will not work on Windows without WinUtils, which contains Windows binaries for Hadoop. This will require admin privileges. More information can be found <a href="https://datathirst.net/blog/2019/4/20/setup-databricks-connect-on-windows">here.</a> Also, make sure that your installation path (includes your username) for Spark does not have a space in it! If it does you can get around it by modifying the Windows registry, which can really screw up your Windows installation! Do this at your own risk! More information can be found <a href="https://datathirst.net/blog/2019/4/20/setup-databricks-connect-on-windows">here.</a></p>
<p>Then run the following command to get the path where the pyspark Java archive files are:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="ex">databricks-connect</span> get-jar-dir</a></code></pre></div>
<p>This will return a path like this</p>
<ul>
<li><p>Windows: <code>C:\\users\\username\\appdata\\local\\continuum\\anaconda3\\envs\\dbconnect\\lib\\site-packages\\pyspark/jars</code></p></li>
<li><p>Mac: <code>/usr/local/lib/python3.7/site-packages/pyspark/jars</code></p></li>
</ul>
<p>Copy the file path of one directory above the JAR directory file path. For example <code>C:\\users\\username\\appdata\\local\\continuum\\anaconda3\\envs\\dbconnect\\lib\\site-packages\\pyspark</code></p>
<p>Now switch over to RStudio. First, install <code>SparkR</code> with command <code>install.packages(&quot;SparkR&quot;)</code>. Then copy the two file directory paths and use them to tell SparkR where to look for Spark and pyspark. On a Windows computer backslashes need to be escaped, therefore the double backslashes in the path names. On a Mac computer the path will have front slashes.</p>
<p>In Windows:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="kw">library</span>(dplyr)</a>
<a class="sourceLine" id="cb8-2" data-line-number="2"></a>
<a class="sourceLine" id="cb8-3" data-line-number="3"><span class="kw">library</span>(SparkR, <span class="dt">lib.loc =</span> <span class="kw">.libPaths</span>(<span class="kw">c</span>(<span class="kw">file.path</span>(<span class="st">&quot;C:</span><span class="ch">\\</span><span class="st">Users</span><span class="ch">\\</span><span class="st">username</span><span class="ch">\\</span><span class="st">AppData</span><span class="ch">\\</span><span class="st">Local</span><span class="ch">\\</span><span class="st">Apache</span><span class="ch">\\</span><span class="st">Spark</span><span class="ch">\\</span><span class="st">Cache</span><span class="ch">\\</span><span class="st">spark-2.4.3-bin-hadoop2.7&quot;</span>, <span class="st">&quot;R&quot;</span>, <span class="st">&quot;lib&quot;</span>), <span class="kw">.libPaths</span>())))</a>
<a class="sourceLine" id="cb8-4" data-line-number="4"></a>
<a class="sourceLine" id="cb8-5" data-line-number="5"><span class="kw">Sys.setenv</span>(<span class="dt">SPARK_HOME =</span> <span class="st">&quot;c:</span><span class="ch">\\</span><span class="st">users</span><span class="ch">\\</span><span class="st">ericle</span><span class="ch">\\</span><span class="st">appdata</span><span class="ch">\\</span><span class="st">local</span><span class="ch">\\</span><span class="st">continuum</span><span class="ch">\\</span><span class="st">anaconda3</span><span class="ch">\\</span><span class="st">envs</span><span class="ch">\\</span><span class="st">dbconnect_6_2</span><span class="ch">\\</span><span class="st">lib</span><span class="ch">\\</span><span class="st">site-packages</span><span class="ch">\\</span><span class="st">pyspark&quot;</span>)</a></code></pre></div>
<p>In Mac:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="kw">library</span>(dplyr)</a>
<a class="sourceLine" id="cb9-2" data-line-number="2"></a>
<a class="sourceLine" id="cb9-3" data-line-number="3"><span class="kw">library</span>(SparkR, <span class="dt">lib.loc =</span> <span class="kw">.libPaths</span>(<span class="kw">c</span>(<span class="kw">file.path</span>(<span class="st">&quot;~/AppData/spark-2.4.5-bin-hadoop2.7/&quot;</span>, <span class="st">&#39;R&#39;</span>, <span class="st">&#39;lib&#39;</span>), <span class="kw">.libPaths</span>())))</a>
<a class="sourceLine" id="cb9-4" data-line-number="4"></a>
<a class="sourceLine" id="cb9-5" data-line-number="5"><span class="kw">Sys.setenv</span>(<span class="dt">SPARK_HOME =</span> <span class="st">&quot;/usr/local/lib/python3.7/site-packages/pyspark/&quot;</span>)</a></code></pre></div>
<p>You should now be able to initiate a Spark session and start running SparkR commands. If your cluster is not running it should start automatically (this might take some minutes).</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1">SparkR<span class="op">::</span><span class="kw">sparkR.session</span>()</a></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1">df &lt;-<span class="st"> </span><span class="kw">as.DataFrame</span>(faithful)</a>
<a class="sourceLine" id="cb11-2" data-line-number="2">df1 &lt;-<span class="st"> </span><span class="kw">dapply</span>(df, <span class="cf">function</span>(x) { x }, <span class="kw">schema</span>(df))</a>
<a class="sourceLine" id="cb11-3" data-line-number="3"><span class="kw">collect</span>(df1)</a></code></pre></div>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1">nba_player_stats &lt;-<span class="st"> </span><span class="kw">read.df</span>(<span class="dt">source =</span> <span class="st">&quot;csv&quot;</span>, <span class="dt">path =</span> <span class="st">&quot;dbfs:/FileStore/tables/nbaplayerstats1519_2-d5cfb.csv&quot;</span>, <span class="dt">header=</span><span class="st">&quot;true&quot;</span>, <span class="dt">inferSchema =</span> <span class="st">&quot;true&quot;</span>, <span class="dt">sep =</span> <span class="st">&#39;;&#39;</span>)</a>
<a class="sourceLine" id="cb12-2" data-line-number="2"></a>
<a class="sourceLine" id="cb12-3" data-line-number="3"><span class="kw">head</span>(nba_player_stats)</a></code></pre></div>
<p>You can stop the Spark session but the cluster will not shut down until the preset autotermination time, or until you terminate it manually.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1">SparkR<span class="op">::</span><span class="kw">sparkR.session.stop</span>()</a></code></pre></div>
</div>
<div id="troubleshoot" class="section level2">
<h2><span class="header-section-number">1.7</span> Troubleshoot</h2>
<div id="mac-error-starting-a-spark-session" class="section level3">
<h3><span class="header-section-number">1.7.1</span> Mac: Error starting a spark session</h3>
<p>In mac starting a new spark session with command <code>SparkR::sparkR.session()</code> might give you an error in console:</p>
<pre><code>Java version 8 is required for this package; found version: 11.0.1</code></pre>
<p>Check installed java version in terminal:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb15-1" data-line-number="1"><span class="fu">ls</span> -l /Library/Java/JavaVirtualMachines</a></code></pre></div>
<p>Set Java version directory in R before running SparkR session command:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1"><span class="kw">Sys.setenv</span>(<span class="dt">JAVA_HOME =</span> <span class="st">&quot;/Library/Java/JavaVirtualMachines/jdk1.8.0_241.jdk/Contents/Home&quot;</span>)</a></code></pre></div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>

<a href="text-mining-with-sparklyr.html" class="navigation navigation-next navigation-unique" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true
});
});
</script>

</body>

</html>
